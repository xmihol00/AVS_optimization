<?xml version='1.0' encoding='UTF-8'?>

<bag xmlns:boolean="http://www.w3.org/2001/XMLSchema#boolean" xmlns:float="http://www.w3.org/2001/XMLSchema#float" xmlns:int="http://www.w3.org/2001/XMLSchema#int" xmlns:unsignedInt="http://www.w3.org/2001/XMLSchema#unsignedInt" xmlns:unsignedLong="http://www.w3.org/2001/XMLSchema#unsignedLong" int:version="16">
 <issues>
  <issue>
   <unsignedInt:flags>321</unsignedInt:flags>
   <id>issue_roofline_guidance</id>
   <int:severity>2</int:severity>
   <text/>
   <title>issue_roofline_guidance_title</title>
   <attributes>
    <float:severity>2</float:severity>
   </attributes>
   <parameters boolean:is_vectorized="true" zone="mem" ops_type="float"/>
   <recommendations>
    <recommendation>
     <int:confidence>2</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_roofline_guidance_memory_bound</id>
     <text>roofline_guidance_memory_bound_text</text>
     <title>This loop is mostly memory bound </title>
     <attributes>
      <float:confidence>2</float:confidence>
     </attributes>
     <parameters>
      <boolean:is_vectorized>true</boolean:is_vectorized>
      <boolean:is_fma_dominated>false</boolean:is_fma_dominated>
      <boolean:scalar_mem_instructions>false</boolean:scalar_mem_instructions>
      <traits>Type Conversions, Inserts, Extracts</traits>
      <boolean:inefficient_map>false</boolean:inefficient_map>
      <boolean:low_vector_efficiency>false</boolean:low_vector_efficiency>
      <int:limiting_roof>3</int:limiting_roof>
     </parameters>
    </recommendation>
    <recommendation>
     <int:confidence>2</int:confidence>
     <unsignedInt:flags>1032</unsignedInt:flags>
     <id>rec_roofline_guidance_collect_all_memory_levels</id>
     <text>rec_roofline_guidance_collect_text</text>
     <title>Collect Roofline for all memory levels </title>
     <attributes>
      <float:confidence>2</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>7</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_type_conversions</id>
   <int:severity>1</int:severity>
   <text>There are multiple data types within loops. Utilize hardware vectorization support more effectively by avoiding data type conversion. </text>
   <title>Data type conversions present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_type_conversions_smallest_c</id>
     <text>The &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;source loop&lt;/a&gt; contains data types of different widths. To fix: Use the smallest data type that gives the needed precision to use the entire &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;vector register width&lt;/a&gt;.
&lt;/br&gt;&lt;b&gt;Example:&lt;/b&gt; If only 16-bits are needed, using a short rather than an int can make the difference between eight-way or four-way SIMD parallelism, respectively. </text>
     <title>Use the smallest data type </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>7</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_type_conversions</id>
   <int:severity>1</int:severity>
   <text>There are multiple data types within loops. Utilize hardware vectorization support more effectively by avoiding data type conversion. </text>
   <title>Data type conversions present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_type_conversions_smallest_c</id>
     <text>The &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;source loop&lt;/a&gt; contains data types of different widths. To fix: Use the smallest data type that gives the needed precision to use the entire &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;vector register width&lt;/a&gt;.
&lt;/br&gt;&lt;b&gt;Example:&lt;/b&gt; If only 16-bits are needed, using a short rather than an int can make the difference between eight-way or four-way SIMD parallelism, respectively. </text>
     <title>Use the smallest data type </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>8</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_type_conversions</id>
   <int:severity>1</int:severity>
   <text>There are multiple data types within loops. Utilize hardware vectorization support more effectively by avoiding data type conversion. </text>
   <title>Data type conversions present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_type_conversions_smallest_c</id>
     <text>The &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;source loop&lt;/a&gt; contains data types of different widths. To fix: Use the smallest data type that gives the needed precision to use the entire &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;vector register width&lt;/a&gt;.
&lt;/br&gt;&lt;b&gt;Example:&lt;/b&gt; If only 16-bits are needed, using a short rather than an int can make the difference between eight-way or four-way SIMD parallelism, respectively. </text>
     <title>Use the smallest data type </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>9</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>66</unsignedInt:flags>
   <id>compiler_diag_issue_15542</id>
   <int:severity>1</int:severity>
   <text>compiler_diag_issue_15542_text</text>
   <title>compiler_diag_issue_15542_title</title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>compiler_diag_rec_15542</id>
     <text>compiler_diag_rec_15542_text</text>
     <title>Recommendations </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>9</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>321</unsignedInt:flags>
   <id>issue_roofline_guidance</id>
   <int:severity>2</int:severity>
   <text/>
   <title>issue_roofline_guidance_title</title>
   <attributes>
    <float:severity>2</float:severity>
   </attributes>
   <parameters boolean:is_vectorized="true" zone="mix" ops_type="float"/>
   <recommendations>
    <recommendation>
     <int:confidence>2</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_roofline_guidance_mostly_memory_bound</id>
     <text>roofline_guidance_mostly_memory_bound_text</text>
     <title>This loop is mostly memory bound but may also be compute bound </title>
     <attributes>
      <float:confidence>2</float:confidence>
     </attributes>
     <parameters>
      <boolean:is_vectorized>true</boolean:is_vectorized>
      <boolean:is_fma_dominated>false</boolean:is_fma_dominated>
      <boolean:scalar_mem_instructions>false</boolean:scalar_mem_instructions>
      <boolean:inefficient_map>false</boolean:inefficient_map>
      <boolean:low_vector_efficiency>false</boolean:low_vector_efficiency>
      <int:limiting_roof>1</int:limiting_roof>
     </parameters>
    </recommendation>
    <recommendation>
     <int:confidence>2</int:confidence>
     <unsignedInt:flags>1032</unsignedInt:flags>
     <id>rec_roofline_guidance_collect_all_memory_levels</id>
     <text>rec_roofline_guidance_collect_text</text>
     <title>Collect Roofline for all memory levels </title>
     <attributes>
      <float:confidence>2</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>10</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>66</unsignedInt:flags>
   <id>compiler_diag_issue_15542</id>
   <int:severity>1</int:severity>
   <text>compiler_diag_issue_15542_text</text>
   <title>compiler_diag_issue_15542_title</title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>compiler_diag_rec_15542</id>
     <text>compiler_diag_rec_15542_text</text>
     <title>Recommendations </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>12</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>66</unsignedInt:flags>
   <id>compiler_diag_issue_15542</id>
   <int:severity>1</int:severity>
   <text>compiler_diag_issue_15542_text</text>
   <title>compiler_diag_issue_15542_title</title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>compiler_diag_rec_15542</id>
     <text>compiler_diag_rec_15542_text</text>
     <title>Recommendations </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>13</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>69</unsignedInt:flags>
   <id>issue_check_access_patterns</id>
   <int:severity>2</int:severity>
   <text>Inefficient memory access patterns may result in significant vector code execution slowdown or block automatic vectorization by the compiler. Improve performance by investigating. </text>
   <title>Possible inefficient memory access patterns present </title>
   <attributes>
    <float:severity>2</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>2</int:confidence>
     <unsignedInt:flags>1032</unsignedInt:flags>
     <id>rec_check_access_patterns_run_map_c</id>
     <text>There is no confirmation inefficient memory access patterns are present. To confirm: Run a &lt;a href=&quot;../help/index.htm#GUID-B98AD81B-4946-4E86-B452-9A1810F4517C.htm&quot;&gt;Memory Access Patterns analysis&lt;/a&gt;. </text>
     <title>Confirm inefficient memory access patterns </title>
     <attributes>
      <float:confidence>2</float:confidence>
     </attributes>
     <parameters>
      <boolean:no_map_disclaimer>true</boolean:no_map_disclaimer>
     </parameters>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>14</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>97</unsignedInt:flags>
   <id>issue_type_conversions</id>
   <int:severity>1</int:severity>
   <text>There are multiple data types within loops. Utilize hardware vectorization support more effectively by avoiding data type conversion. </text>
   <title>Data type conversions present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>40</unsignedInt:flags>
     <id>rec_type_conversions_smallest_c</id>
     <text>The &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;source loop&lt;/a&gt; contains data types of different widths. To fix: Use the smallest data type that gives the needed precision to use the entire &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;vector register width&lt;/a&gt;.
&lt;/br&gt;&lt;b&gt;Example:&lt;/b&gt; If only 16-bits are needed, using a short rather than an int can make the difference between eight-way or four-way SIMD parallelism, respectively. </text>
     <title>Use the smallest data type </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>17</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>98</unsignedInt:flags>
   <id>compiler_diag_issue_15316</id>
   <int:severity>1</int:severity>
   <text>&lt;b&gt;Cause:&lt;/b&gt; In nested loop structures, the compiler targets the innermost loop for vectorization. The outer loop, by default, is not a target for vectorization; however, it may be a target for parallelization.&lt;br/&gt; &lt;b&gt;C++ Example:&lt;/b&gt; &lt;div class=&quot;sample&quot;&gt;&lt;br/&gt;
#include &amp;lt;iostream&amp;gt; &lt;br/&gt;
#define N 25&lt;br/&gt;
int main()&lt;br/&gt;
{&lt;br/&gt;
&amp;nbsp;&amp;nbsp;int a[N][N], b[N], i;&lt;br/&gt;
&amp;nbsp;&amp;nbsp;for(int j = 0; j &amp;lt; N; j++)&lt;br/&gt;
&amp;nbsp;&amp;nbsp;{&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;for(int i = 0; i &amp;lt; N; i++)&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;a[j][i] = 0;&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;b[j] = 1;&lt;br/&gt;
&amp;nbsp;&amp;nbsp;}&lt;br/&gt;
&amp;nbsp;&amp;nbsp;int sum = __sec_reduce_add(a[:][:]) + __sec_reduce_add(b[:]);&lt;br/&gt;
&amp;nbsp;&amp;nbsp;return 0;&lt;br/&gt;
}&lt;/div&gt; </text>
   <title>Not inner loop </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>40</unsignedInt:flags>
     <id>compiler_diag_rec_15316</id>
     <text>In some cases it is possible to collapse a nested loop structure into a single loop structure using a directive before the outer loop. The &lt;div class=&quot;inplace_sample&quot;&gt;n&lt;/div&gt; argument is an integer that specifies how many loops to collapse into one loop for vectorization. &lt;table&gt; &lt;tr&gt; &lt;th&gt;Target &lt;/th&gt; &lt;th&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;ICL/ICC/ICPC&lt;/a&gt; Directive &lt;/th&gt; &lt;th&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;IFORT&lt;/a&gt; Directive &lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Outer loop&lt;/td&gt; &lt;td&gt;#pragma omp simd collapse(n), #pragma omp simd, or #pragma simd&lt;/td&gt; &lt;td&gt;!$OMP SIMD COLLAPSE(n), !$OMP SIMD, or !DIR$ SIMD&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;b&gt;Read More C++ Information:&lt;/b&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/cdiag15316&quot;&gt;https://software.intel.com/en-us/articles/cdiag15316&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;C++/17/index.htm#GUID-4D8CDB9C-8A96-4CB2-B5E5-3D81003FE4FF.html&gt;omp simd&lt;/a&gt;, &lt;a href=&quot;C++/17/index.htm#GUID-1EA04294-988E-4152-B584-B028FD6FAC48.html&quot;&gt;simd&lt;/a&gt; &lt;li&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/getting-started-with-intel-composer-xe-2013-compiler-pragmas-and-directives&quot;&gt;Getting Started with Intel Compiler Pragmas and Directives&lt;/a&gt; and &lt;a href=&quot;https://software.intel.com/en-us/vectorization-resources-advisor&quot;&gt;Vectorization Resources for Intel&amp;reg; Advisor Users&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;  </text>
     <title>Recommendations </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>17</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>98</unsignedInt:flags>
   <id>compiler_diag_issue_15316</id>
   <int:severity>1</int:severity>
   <text>&lt;b&gt;Cause:&lt;/b&gt; In nested loop structures, the compiler targets the innermost loop for vectorization. The outer loop, by default, is not a target for vectorization; however, it may be a target for parallelization.&lt;br/&gt; &lt;b&gt;C++ Example:&lt;/b&gt; &lt;div class=&quot;sample&quot;&gt;&lt;br/&gt;
#include &amp;lt;iostream&amp;gt; &lt;br/&gt;
#define N 25&lt;br/&gt;
int main()&lt;br/&gt;
{&lt;br/&gt;
&amp;nbsp;&amp;nbsp;int a[N][N], b[N], i;&lt;br/&gt;
&amp;nbsp;&amp;nbsp;for(int j = 0; j &amp;lt; N; j++)&lt;br/&gt;
&amp;nbsp;&amp;nbsp;{&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;for(int i = 0; i &amp;lt; N; i++)&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;a[j][i] = 0;&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;b[j] = 1;&lt;br/&gt;
&amp;nbsp;&amp;nbsp;}&lt;br/&gt;
&amp;nbsp;&amp;nbsp;int sum = __sec_reduce_add(a[:][:]) + __sec_reduce_add(b[:]);&lt;br/&gt;
&amp;nbsp;&amp;nbsp;return 0;&lt;br/&gt;
}&lt;/div&gt; </text>
   <title>Not inner loop </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>40</unsignedInt:flags>
     <id>compiler_diag_rec_15316</id>
     <text>In some cases it is possible to collapse a nested loop structure into a single loop structure using a directive before the outer loop. The &lt;div class=&quot;inplace_sample&quot;&gt;n&lt;/div&gt; argument is an integer that specifies how many loops to collapse into one loop for vectorization. &lt;table&gt; &lt;tr&gt; &lt;th&gt;Target &lt;/th&gt; &lt;th&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;ICL/ICC/ICPC&lt;/a&gt; Directive &lt;/th&gt; &lt;th&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;IFORT&lt;/a&gt; Directive &lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Outer loop&lt;/td&gt; &lt;td&gt;#pragma omp simd collapse(n), #pragma omp simd, or #pragma simd&lt;/td&gt; &lt;td&gt;!$OMP SIMD COLLAPSE(n), !$OMP SIMD, or !DIR$ SIMD&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;b&gt;Read More C++ Information:&lt;/b&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/cdiag15316&quot;&gt;https://software.intel.com/en-us/articles/cdiag15316&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;C++/17/index.htm#GUID-4D8CDB9C-8A96-4CB2-B5E5-3D81003FE4FF.html&gt;omp simd&lt;/a&gt;, &lt;a href=&quot;C++/17/index.htm#GUID-1EA04294-988E-4152-B584-B028FD6FAC48.html&quot;&gt;simd&lt;/a&gt; &lt;li&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/getting-started-with-intel-composer-xe-2013-compiler-pragmas-and-directives&quot;&gt;Getting Started with Intel Compiler Pragmas and Directives&lt;/a&gt; and &lt;a href=&quot;https://software.intel.com/en-us/vectorization-resources-advisor&quot;&gt;Vectorization Resources for Intel&amp;reg; Advisor Users&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;  </text>
     <title>Recommendations </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>18</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>98</unsignedInt:flags>
   <id>compiler_diag_issue_15335</id>
   <int:severity>1</int:severity>
   <text>compiler_diag_issue_15335_text</text>
   <title>compiler_diag_issue_15335_title</title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>40</unsignedInt:flags>
     <id>compiler_diag_rec_15335</id>
     <text>compiler_diag_rec_15335_text</text>
     <title>Recommendations </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>19</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>321</unsignedInt:flags>
   <id>issue_roofline_guidance</id>
   <int:severity>2</int:severity>
   <text/>
   <title>issue_roofline_guidance_title</title>
   <attributes>
    <float:severity>2</float:severity>
   </attributes>
   <parameters boolean:is_vectorized="true" zone="mem" ops_type="float"/>
   <recommendations>
    <recommendation>
     <int:confidence>2</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_roofline_guidance_memory_bound</id>
     <text>roofline_guidance_memory_bound_text</text>
     <title>This loop is mostly memory bound </title>
     <attributes>
      <float:confidence>2</float:confidence>
     </attributes>
     <parameters>
      <boolean:is_vectorized>true</boolean:is_vectorized>
      <boolean:is_fma_dominated>false</boolean:is_fma_dominated>
      <boolean:scalar_mem_instructions>false</boolean:scalar_mem_instructions>
      <traits>Extracts, Inserts, Type Conversions, [FMA, Type Conversions]</traits>
      <boolean:inefficient_map>false</boolean:inefficient_map>
      <boolean:low_vector_efficiency>false</boolean:low_vector_efficiency>
      <int:limiting_roof>3</int:limiting_roof>
     </parameters>
    </recommendation>
    <recommendation>
     <int:confidence>2</int:confidence>
     <unsignedInt:flags>1032</unsignedInt:flags>
     <id>rec_roofline_guidance_collect_all_memory_levels</id>
     <text>rec_roofline_guidance_collect_text</text>
     <title>Collect Roofline for all memory levels </title>
     <attributes>
      <float:confidence>2</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>25</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>578</unsignedInt:flags>
   <id>compiler_diag_issue_0</id>
   <int:severity>1</int:severity>
   <text/>
   <title/>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations/>
   <unsignedLong:rowKey>25</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>98</unsignedInt:flags>
   <id>compiler_diag_issue_15316</id>
   <int:severity>1</int:severity>
   <text>&lt;b&gt;Cause:&lt;/b&gt; In nested loop structures, the compiler targets the innermost loop for vectorization. The outer loop, by default, is not a target for vectorization; however, it may be a target for parallelization.&lt;br/&gt; &lt;b&gt;C++ Example:&lt;/b&gt; &lt;div class=&quot;sample&quot;&gt;&lt;br/&gt;
#include &amp;lt;iostream&amp;gt; &lt;br/&gt;
#define N 25&lt;br/&gt;
int main()&lt;br/&gt;
{&lt;br/&gt;
&amp;nbsp;&amp;nbsp;int a[N][N], b[N], i;&lt;br/&gt;
&amp;nbsp;&amp;nbsp;for(int j = 0; j &amp;lt; N; j++)&lt;br/&gt;
&amp;nbsp;&amp;nbsp;{&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;for(int i = 0; i &amp;lt; N; i++)&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;a[j][i] = 0;&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;b[j] = 1;&lt;br/&gt;
&amp;nbsp;&amp;nbsp;}&lt;br/&gt;
&amp;nbsp;&amp;nbsp;int sum = __sec_reduce_add(a[:][:]) + __sec_reduce_add(b[:]);&lt;br/&gt;
&amp;nbsp;&amp;nbsp;return 0;&lt;br/&gt;
}&lt;/div&gt; </text>
   <title>Not inner loop </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters>
    <int:impure_presence>1</int:impure_presence>
    <int:all_children>2</int:all_children>
    <int:children_w_rec>1</int:children_w_rec>
   </parameters>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>40</unsignedInt:flags>
     <id>compiler_diag_rec_15316</id>
     <text>In some cases it is possible to collapse a nested loop structure into a single loop structure using a directive before the outer loop. The &lt;div class=&quot;inplace_sample&quot;&gt;n&lt;/div&gt; argument is an integer that specifies how many loops to collapse into one loop for vectorization. &lt;table&gt; &lt;tr&gt; &lt;th&gt;Target &lt;/th&gt; &lt;th&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;ICL/ICC/ICPC&lt;/a&gt; Directive &lt;/th&gt; &lt;th&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;IFORT&lt;/a&gt; Directive &lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Outer loop&lt;/td&gt; &lt;td&gt;#pragma omp simd collapse(n), #pragma omp simd, or #pragma simd&lt;/td&gt; &lt;td&gt;!$OMP SIMD COLLAPSE(n), !$OMP SIMD, or !DIR$ SIMD&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;b&gt;Read More C++ Information:&lt;/b&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/cdiag15316&quot;&gt;https://software.intel.com/en-us/articles/cdiag15316&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;C++/17/index.htm#GUID-4D8CDB9C-8A96-4CB2-B5E5-3D81003FE4FF.html&gt;omp simd&lt;/a&gt;, &lt;a href=&quot;C++/17/index.htm#GUID-1EA04294-988E-4152-B584-B028FD6FAC48.html&quot;&gt;simd&lt;/a&gt; &lt;li&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/getting-started-with-intel-composer-xe-2013-compiler-pragmas-and-directives&quot;&gt;Getting Started with Intel Compiler Pragmas and Directives&lt;/a&gt; and &lt;a href=&quot;https://software.intel.com/en-us/vectorization-resources-advisor&quot;&gt;Vectorization Resources for Intel&amp;reg; Advisor Users&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;  </text>
     <title>Recommendations </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>25</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_type_conversions</id>
   <int:severity>1</int:severity>
   <text>There are multiple data types within loops. Utilize hardware vectorization support more effectively by avoiding data type conversion. </text>
   <title>Data type conversions present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_type_conversions_smallest_c</id>
     <text>The &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;source loop&lt;/a&gt; contains data types of different widths. To fix: Use the smallest data type that gives the needed precision to use the entire &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;vector register width&lt;/a&gt;.
&lt;/br&gt;&lt;b&gt;Example:&lt;/b&gt; If only 16-bits are needed, using a short rather than an int can make the difference between eight-way or four-way SIMD parallelism, respectively. </text>
     <title>Use the smallest data type </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>25</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>321</unsignedInt:flags>
   <id>issue_roofline_guidance</id>
   <int:severity>2</int:severity>
   <text/>
   <title>issue_roofline_guidance_title</title>
   <attributes>
    <float:severity>2</float:severity>
   </attributes>
   <parameters boolean:is_vectorized="true" zone="mix" ops_type="float"/>
   <recommendations>
    <recommendation>
     <int:confidence>2</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_roofline_guidance_mostly_memory_bound</id>
     <text>roofline_guidance_mostly_memory_bound_text</text>
     <title>This loop is mostly memory bound but may also be compute bound </title>
     <attributes>
      <float:confidence>2</float:confidence>
     </attributes>
     <parameters>
      <boolean:is_vectorized>true</boolean:is_vectorized>
      <boolean:is_fma_dominated>false</boolean:is_fma_dominated>
      <boolean:scalar_mem_instructions>false</boolean:scalar_mem_instructions>
      <traits>[FMA]</traits>
      <boolean:inefficient_map>false</boolean:inefficient_map>
      <boolean:low_vector_efficiency>false</boolean:low_vector_efficiency>
      <int:limiting_roof>1</int:limiting_roof>
     </parameters>
    </recommendation>
    <recommendation>
     <int:confidence>2</int:confidence>
     <unsignedInt:flags>1032</unsignedInt:flags>
     <id>rec_roofline_guidance_collect_all_memory_levels</id>
     <text>rec_roofline_guidance_collect_text</text>
     <title>Collect Roofline for all memory levels </title>
     <attributes>
      <float:confidence>2</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>26</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>578</unsignedInt:flags>
   <id>compiler_diag_issue_0</id>
   <int:severity>1</int:severity>
   <text/>
   <title/>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations/>
   <unsignedLong:rowKey>26</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>98</unsignedInt:flags>
   <id>compiler_diag_issue_15316</id>
   <int:severity>1</int:severity>
   <text>&lt;b&gt;Cause:&lt;/b&gt; In nested loop structures, the compiler targets the innermost loop for vectorization. The outer loop, by default, is not a target for vectorization; however, it may be a target for parallelization.&lt;br/&gt; &lt;b&gt;C++ Example:&lt;/b&gt; &lt;div class=&quot;sample&quot;&gt;&lt;br/&gt;
#include &amp;lt;iostream&amp;gt; &lt;br/&gt;
#define N 25&lt;br/&gt;
int main()&lt;br/&gt;
{&lt;br/&gt;
&amp;nbsp;&amp;nbsp;int a[N][N], b[N], i;&lt;br/&gt;
&amp;nbsp;&amp;nbsp;for(int j = 0; j &amp;lt; N; j++)&lt;br/&gt;
&amp;nbsp;&amp;nbsp;{&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;for(int i = 0; i &amp;lt; N; i++)&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;a[j][i] = 0;&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;b[j] = 1;&lt;br/&gt;
&amp;nbsp;&amp;nbsp;}&lt;br/&gt;
&amp;nbsp;&amp;nbsp;int sum = __sec_reduce_add(a[:][:]) + __sec_reduce_add(b[:]);&lt;br/&gt;
&amp;nbsp;&amp;nbsp;return 0;&lt;br/&gt;
}&lt;/div&gt; </text>
   <title>Not inner loop </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters>
    <int:impure_presence>1</int:impure_presence>
    <int:all_children>2</int:all_children>
    <int:children_w_rec>1</int:children_w_rec>
   </parameters>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>40</unsignedInt:flags>
     <id>compiler_diag_rec_15316</id>
     <text>In some cases it is possible to collapse a nested loop structure into a single loop structure using a directive before the outer loop. The &lt;div class=&quot;inplace_sample&quot;&gt;n&lt;/div&gt; argument is an integer that specifies how many loops to collapse into one loop for vectorization. &lt;table&gt; &lt;tr&gt; &lt;th&gt;Target &lt;/th&gt; &lt;th&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;ICL/ICC/ICPC&lt;/a&gt; Directive &lt;/th&gt; &lt;th&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;IFORT&lt;/a&gt; Directive &lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Outer loop&lt;/td&gt; &lt;td&gt;#pragma omp simd collapse(n), #pragma omp simd, or #pragma simd&lt;/td&gt; &lt;td&gt;!$OMP SIMD COLLAPSE(n), !$OMP SIMD, or !DIR$ SIMD&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;b&gt;Read More C++ Information:&lt;/b&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/cdiag15316&quot;&gt;https://software.intel.com/en-us/articles/cdiag15316&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;C++/17/index.htm#GUID-4D8CDB9C-8A96-4CB2-B5E5-3D81003FE4FF.html&gt;omp simd&lt;/a&gt;, &lt;a href=&quot;C++/17/index.htm#GUID-1EA04294-988E-4152-B584-B028FD6FAC48.html&quot;&gt;simd&lt;/a&gt; &lt;li&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/getting-started-with-intel-composer-xe-2013-compiler-pragmas-and-directives&quot;&gt;Getting Started with Intel Compiler Pragmas and Directives&lt;/a&gt; and &lt;a href=&quot;https://software.intel.com/en-us/vectorization-resources-advisor&quot;&gt;Vectorization Resources for Intel&amp;reg; Advisor Users&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;  </text>
     <title>Recommendations </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>26</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>69</unsignedInt:flags>
   <id>issue_check_access_patterns</id>
   <int:severity>2</int:severity>
   <text>Inefficient memory access patterns may result in significant vector code execution slowdown or block automatic vectorization by the compiler. Improve performance by investigating. </text>
   <title>Possible inefficient memory access patterns present </title>
   <attributes>
    <float:severity>2</float:severity>
   </attributes>
   <parameters>
    <int:impure_presence>1</int:impure_presence>
    <int:all_children>2</int:all_children>
    <int:children_w_rec>1</int:children_w_rec>
   </parameters>
   <recommendations>
    <recommendation>
     <int:confidence>2</int:confidence>
     <unsignedInt:flags>1032</unsignedInt:flags>
     <id>rec_check_access_patterns_run_map_c</id>
     <text>There is no confirmation inefficient memory access patterns are present. To confirm: Run a &lt;a href=&quot;../help/index.htm#GUID-B98AD81B-4946-4E86-B452-9A1810F4517C.htm&quot;&gt;Memory Access Patterns analysis&lt;/a&gt;. </text>
     <title>Confirm inefficient memory access patterns </title>
     <attributes>
      <float:confidence>2</float:confidence>
     </attributes>
     <parameters>
      <boolean:no_map_disclaimer>true</boolean:no_map_disclaimer>
     </parameters>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>27</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>578</unsignedInt:flags>
   <id>compiler_diag_issue_0</id>
   <int:severity>1</int:severity>
   <text/>
   <title/>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations/>
   <unsignedLong:rowKey>27</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>98</unsignedInt:flags>
   <id>compiler_diag_issue_15335</id>
   <int:severity>1</int:severity>
   <text>compiler_diag_issue_15335_text</text>
   <title>compiler_diag_issue_15335_title</title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters>
    <int:impure_presence>1</int:impure_presence>
    <int:all_children>2</int:all_children>
    <int:children_w_rec>1</int:children_w_rec>
   </parameters>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>40</unsignedInt:flags>
     <id>compiler_diag_rec_15335</id>
     <text>compiler_diag_rec_15335_text</text>
     <title>Recommendations </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>27</unsignedLong:rowKey>
  </issue>
 </issues>
 <traits>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>4</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>5</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>6</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>35</int:fieldId>
   <int:id>12</int:id>
   <text>Vector Length Was Set Manually 
16 Elements of Float32 Data Type Fits in avx512 Vector Register </text>
   <unsignedLong:rowKey>10</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>44</int:fieldId>
   <int:id>2</int:id>
   <text>Irregular Memory Access Patterns May Decrease Performance 
Suggestion: See Recommendations Tab </text>
   <unsignedLong:rowKey>14</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>16</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>35</int:fieldId>
   <int:id>12</int:id>
   <text>Vector Length Was Set Manually 
16 Elements of Float32 Data Type Fits in avx512 Vector Register </text>
   <unsignedLong:rowKey>26</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>44</int:fieldId>
   <int:id>2</int:id>
   <text>Irregular Memory Access Patterns May Decrease Performance 
Suggestion: See Recommendations Tab </text>
   <unsignedLong:rowKey>27</unsignedLong:rowKey>
  </trait>
 </traits>
</bag>
